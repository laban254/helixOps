# HelixOps Configuration

# Application settings
app:
  host: "0.0.0.0"
  port: 8080
  log_level: "info"

# Prometheus configuration
prometheus:
  url: "http://prometheus:9090"
  timeout: "30s"

# Loki configuration
loki:
  url: "http://loki:3100"
  timeout: "30s"

# GitHub configuration
github:
  api_url: "https://api.github.com"
  # Token is loaded from GITHUB_TOKEN environment variable

# Tempo configuration
tempo:
  url: "http://tempo:3200"
  enabled: true
  slow_span_threshold_ms: 500
  search_limit: 20

# LLM configuration
llm:
  provider: "ollama"  # Options: openai, anthropic, ollama
  model: "gpt-4o"
  temperature: 0.1
  max_tokens: 1000
  # API key is loaded from OPENAI_API_KEY or ANTHROPIC_API_KEY environment variable
  ollama_url: "http://ollama:11434"
  ollama_model: "llama2"

# Output channels
output:
  slack:
    webhook_url_env: "SLACK_WEBHOOK_URL"
    enabled: true
  discord:
    webhook_url_env: "DISCORD_WEBHOOK_URL"
    enabled: false
  markdown:
    output_dir: "./reports"
    enabled: true

# Analysis settings
analysis:
  metrics_window: "15m"
  commits_lookback: "24h"
  logs_lookback: "1h"
